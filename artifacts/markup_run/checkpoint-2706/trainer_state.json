{
  "best_global_step": 2706,
  "best_metric": 0.9182704106513963,
  "best_model_checkpoint": "artifacts/markup_run/checkpoint-2706",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2706,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018477457501847747,
      "grad_norm": 4.515512943267822,
      "learning_rate": 9.01840490797546e-06,
      "loss": 0.6966,
      "step": 50
    },
    {
      "epoch": 0.03695491500369549,
      "grad_norm": 4.2026472091674805,
      "learning_rate": 1.8220858895705523e-05,
      "loss": 0.6076,
      "step": 100
    },
    {
      "epoch": 0.05543237250554324,
      "grad_norm": 19.357845306396484,
      "learning_rate": 2.7423312883435586e-05,
      "loss": 0.5607,
      "step": 150
    },
    {
      "epoch": 0.07390983000739099,
      "grad_norm": 28.816776275634766,
      "learning_rate": 2.9575304758159657e-05,
      "loss": 0.509,
      "step": 200
    },
    {
      "epoch": 0.09238728750923873,
      "grad_norm": 3.9303956031799316,
      "learning_rate": 2.898545025560362e-05,
      "loss": 0.5848,
      "step": 250
    },
    {
      "epoch": 0.11086474501108648,
      "grad_norm": 8.044004440307617,
      "learning_rate": 2.839559575304758e-05,
      "loss": 0.5884,
      "step": 300
    },
    {
      "epoch": 0.1293422025129342,
      "grad_norm": 9.896265029907227,
      "learning_rate": 2.7805741250491545e-05,
      "loss": 0.4594,
      "step": 350
    },
    {
      "epoch": 0.14781966001478197,
      "grad_norm": 91.02662658691406,
      "learning_rate": 2.721588674793551e-05,
      "loss": 0.5963,
      "step": 400
    },
    {
      "epoch": 0.1662971175166297,
      "grad_norm": 27.517818450927734,
      "learning_rate": 2.662603224537947e-05,
      "loss": 0.5332,
      "step": 450
    },
    {
      "epoch": 0.18477457501847747,
      "grad_norm": 62.60728454589844,
      "learning_rate": 2.6036177742823436e-05,
      "loss": 0.5772,
      "step": 500
    },
    {
      "epoch": 0.2032520325203252,
      "grad_norm": 51.426231384277344,
      "learning_rate": 2.54463232402674e-05,
      "loss": 0.5677,
      "step": 550
    },
    {
      "epoch": 0.22172949002217296,
      "grad_norm": 29.044864654541016,
      "learning_rate": 2.4856468737711366e-05,
      "loss": 0.4256,
      "step": 600
    },
    {
      "epoch": 0.2402069475240207,
      "grad_norm": 1.2343332767486572,
      "learning_rate": 2.4266614235155327e-05,
      "loss": 0.488,
      "step": 650
    },
    {
      "epoch": 0.2586844050258684,
      "grad_norm": 0.39204928278923035,
      "learning_rate": 2.3676759732599292e-05,
      "loss": 0.4584,
      "step": 700
    },
    {
      "epoch": 0.2771618625277162,
      "grad_norm": 45.74176025390625,
      "learning_rate": 2.3086905230043257e-05,
      "loss": 0.3976,
      "step": 750
    },
    {
      "epoch": 0.29563932002956395,
      "grad_norm": 20.174043655395508,
      "learning_rate": 2.249705072748722e-05,
      "loss": 0.4287,
      "step": 800
    },
    {
      "epoch": 0.31411677753141165,
      "grad_norm": 8.185586929321289,
      "learning_rate": 2.1907196224931183e-05,
      "loss": 0.3378,
      "step": 850
    },
    {
      "epoch": 0.3325942350332594,
      "grad_norm": 22.299156188964844,
      "learning_rate": 2.1317341722375148e-05,
      "loss": 0.2403,
      "step": 900
    },
    {
      "epoch": 0.35107169253510717,
      "grad_norm": 184.09173583984375,
      "learning_rate": 2.0727487219819113e-05,
      "loss": 0.5092,
      "step": 950
    },
    {
      "epoch": 0.36954915003695493,
      "grad_norm": 0.18938907980918884,
      "learning_rate": 2.0137632717263078e-05,
      "loss": 0.3545,
      "step": 1000
    },
    {
      "epoch": 0.38802660753880264,
      "grad_norm": 0.2713436782360077,
      "learning_rate": 1.954777821470704e-05,
      "loss": 0.4507,
      "step": 1050
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 0.2247493863105774,
      "learning_rate": 1.8957923712151004e-05,
      "loss": 0.3476,
      "step": 1100
    },
    {
      "epoch": 0.42498152254249816,
      "grad_norm": 9.116900444030762,
      "learning_rate": 1.836806920959497e-05,
      "loss": 0.4117,
      "step": 1150
    },
    {
      "epoch": 0.4434589800443459,
      "grad_norm": 0.6006055474281311,
      "learning_rate": 1.7778214707038933e-05,
      "loss": 0.3375,
      "step": 1200
    },
    {
      "epoch": 0.4619364375461936,
      "grad_norm": 0.5468438267707825,
      "learning_rate": 1.7188360204482895e-05,
      "loss": 0.4795,
      "step": 1250
    },
    {
      "epoch": 0.4804138950480414,
      "grad_norm": 19.074642181396484,
      "learning_rate": 1.659850570192686e-05,
      "loss": 0.4269,
      "step": 1300
    },
    {
      "epoch": 0.49889135254988914,
      "grad_norm": 0.3552738428115845,
      "learning_rate": 1.6008651199370824e-05,
      "loss": 0.3496,
      "step": 1350
    },
    {
      "epoch": 0.5173688100517368,
      "grad_norm": 228.06858825683594,
      "learning_rate": 1.5418796696814786e-05,
      "loss": 0.3688,
      "step": 1400
    },
    {
      "epoch": 0.5358462675535847,
      "grad_norm": 0.2156648188829422,
      "learning_rate": 1.482894219425875e-05,
      "loss": 0.3827,
      "step": 1450
    },
    {
      "epoch": 0.5543237250554324,
      "grad_norm": 0.3201255202293396,
      "learning_rate": 1.4239087691702714e-05,
      "loss": 0.3352,
      "step": 1500
    },
    {
      "epoch": 0.5728011825572801,
      "grad_norm": 1.7007973194122314,
      "learning_rate": 1.3649233189146679e-05,
      "loss": 0.4598,
      "step": 1550
    },
    {
      "epoch": 0.5912786400591279,
      "grad_norm": 9.563708305358887,
      "learning_rate": 1.3059378686590642e-05,
      "loss": 0.2375,
      "step": 1600
    },
    {
      "epoch": 0.6097560975609756,
      "grad_norm": 0.4010172486305237,
      "learning_rate": 1.2469524184034607e-05,
      "loss": 0.4164,
      "step": 1650
    },
    {
      "epoch": 0.6282335550628233,
      "grad_norm": 4.395754337310791,
      "learning_rate": 1.1879669681478568e-05,
      "loss": 0.5443,
      "step": 1700
    },
    {
      "epoch": 0.6467110125646711,
      "grad_norm": 0.08259455859661102,
      "learning_rate": 1.1289815178922533e-05,
      "loss": 0.2753,
      "step": 1750
    },
    {
      "epoch": 0.6651884700665188,
      "grad_norm": 0.22737929224967957,
      "learning_rate": 1.0699960676366496e-05,
      "loss": 0.4332,
      "step": 1800
    },
    {
      "epoch": 0.6836659275683666,
      "grad_norm": 0.08715873211622238,
      "learning_rate": 1.0110106173810461e-05,
      "loss": 0.3375,
      "step": 1850
    },
    {
      "epoch": 0.7021433850702143,
      "grad_norm": 0.220886692404747,
      "learning_rate": 9.520251671254424e-06,
      "loss": 0.2345,
      "step": 1900
    },
    {
      "epoch": 0.720620842572062,
      "grad_norm": 0.140623077750206,
      "learning_rate": 8.930397168698389e-06,
      "loss": 0.3329,
      "step": 1950
    },
    {
      "epoch": 0.7390983000739099,
      "grad_norm": 0.6031569838523865,
      "learning_rate": 8.340542666142352e-06,
      "loss": 0.55,
      "step": 2000
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 0.1230044960975647,
      "learning_rate": 7.750688163586317e-06,
      "loss": 0.3342,
      "step": 2050
    },
    {
      "epoch": 0.7760532150776053,
      "grad_norm": 7.9582061767578125,
      "learning_rate": 7.160833661030279e-06,
      "loss": 0.2961,
      "step": 2100
    },
    {
      "epoch": 0.7945306725794531,
      "grad_norm": 0.2787458002567291,
      "learning_rate": 6.570979158474243e-06,
      "loss": 0.3529,
      "step": 2150
    },
    {
      "epoch": 0.8130081300813008,
      "grad_norm": 0.07842914760112762,
      "learning_rate": 5.981124655918207e-06,
      "loss": 0.2436,
      "step": 2200
    },
    {
      "epoch": 0.8314855875831486,
      "grad_norm": 67.65770721435547,
      "learning_rate": 5.391270153362171e-06,
      "loss": 0.3132,
      "step": 2250
    },
    {
      "epoch": 0.8499630450849963,
      "grad_norm": 0.7637702226638794,
      "learning_rate": 4.801415650806135e-06,
      "loss": 0.3802,
      "step": 2300
    },
    {
      "epoch": 0.868440502586844,
      "grad_norm": 0.28058329224586487,
      "learning_rate": 4.211561148250098e-06,
      "loss": 0.5259,
      "step": 2350
    },
    {
      "epoch": 0.8869179600886918,
      "grad_norm": 3.057368755340576,
      "learning_rate": 3.6217066456940625e-06,
      "loss": 0.3528,
      "step": 2400
    },
    {
      "epoch": 0.9053954175905395,
      "grad_norm": 0.38601094484329224,
      "learning_rate": 3.031852143138026e-06,
      "loss": 0.419,
      "step": 2450
    },
    {
      "epoch": 0.9238728750923872,
      "grad_norm": 0.7256500124931335,
      "learning_rate": 2.44199764058199e-06,
      "loss": 0.2098,
      "step": 2500
    },
    {
      "epoch": 0.9423503325942351,
      "grad_norm": 0.2999561131000519,
      "learning_rate": 1.8521431380259535e-06,
      "loss": 0.2691,
      "step": 2550
    },
    {
      "epoch": 0.9608277900960828,
      "grad_norm": 7.242503643035889,
      "learning_rate": 1.2622886354699173e-06,
      "loss": 0.1513,
      "step": 2600
    },
    {
      "epoch": 0.9793052475979305,
      "grad_norm": 1.9288979768753052,
      "learning_rate": 6.724341329138813e-07,
      "loss": 0.2449,
      "step": 2650
    },
    {
      "epoch": 0.9977827050997783,
      "grad_norm": 0.2888266146183014,
      "learning_rate": 8.257963035784507e-08,
      "loss": 0.1907,
      "step": 2700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.38071003556251526,
      "eval_pr_auc": 0.9182704106513963,
      "eval_roc_auc": 0.9498833987215013,
      "eval_runtime": 97.2005,
      "eval_samples_per_second": 9.486,
      "eval_steps_per_second": 2.377,
      "step": 2706
    }
  ],
  "logging_steps": 50,
  "max_steps": 2706,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3126770486237328.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
